{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Jk3zTAMSv2W"
   },
   "source": [
    "# Installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oH8B_KvNjic",
    "outputId": "1ff40562-fb08-4215-a6d7-dd898009d7fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 29 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 58.5 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=d9f19340b8a47a985414cdb18ae8845051fac653b31ee6caad58852bea9c70ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting Fuzzy\n",
      "  Downloading Fuzzy-1.2.2.tar.gz (14 kB)\n",
      "Building wheels for collected packages: Fuzzy\n",
      "  Building wheel for Fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Fuzzy: filename=Fuzzy-1.2.2-cp37-cp37m-linux_x86_64.whl size=164032 sha256=a4fb26fb8ac52e091e0c80d1fef5eff97dfe4868d4d77592c5ebc2ced928eaee\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/52/8a/bb2d05fbf343752a8546682cb5b2d775cc0d1f27f6c43f95dd\n",
      "Successfully built Fuzzy\n",
      "Installing collected packages: Fuzzy\n",
      "Successfully installed Fuzzy-1.2.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting phonetics\n",
      "  Downloading phonetics-1.0.5.tar.gz (8.8 kB)\n",
      "Building wheels for collected packages: phonetics\n",
      "  Building wheel for phonetics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for phonetics: filename=phonetics-1.0.5-py2.py3-none-any.whl size=8711 sha256=4bfed0966219614fd7036eb348c392c5f97030656647c80d934f87f4e7f3a320\n",
      "  Stored in directory: /root/.cache/pip/wheels/c2/c9/f4/5f43d3212d0aece0feced2484127ddb227ae43d57102aeb259\n",
      "Successfully built phonetics\n",
      "Installing collected packages: phonetics\n",
      "Successfully installed phonetics-1.0.5\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark\n",
    "!pip3 install Fuzzy\n",
    "!pip3 install phonetics\n",
    "!pip3 install requests\n",
    "!pip3 install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWMX5J3UqvbO"
   },
   "source": [
    "# Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77mEEKUCxH-t",
    "outputId": "e61790e3-8ebe-4d5a-db9c-93678b89bdcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAQfTBL4TInL"
   },
   "source": [
    "# Importing required pacakges and initializing the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulD8KUfbPV4v"
   },
   "outputs": [],
   "source": [
    "import fuzzy\n",
    "import phonetics\n",
    "import difflib\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = (SparkConf().setMaster(\"local\").setAppName(\"Phonetic Search\").set(\"spark. executor.memory\",   \"lg\"))\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMYb2Ra8B9hw"
   },
   "source": [
    "# Creating Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wAAJzY_CG2h"
   },
   "outputs": [],
   "source": [
    "urls = [i for i in range(1,115)]\n",
    "rdd_urls = sc.parallelize(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFmgleTqq0OI"
   },
   "source": [
    "# Web Crawler for fetching data from https://quran411.com/verse-by-verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOwsTSjBCdei"
   },
   "outputs": [],
   "source": [
    "def generate_N_grams(text,ngram=1):\n",
    "    words=[word for word in text.split(\" \")]\n",
    "    if(len(words)>=5):\n",
    "        temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "        ans=[' '.join(ngram) for ngram in temp]\n",
    "        return ans\n",
    "    else:\n",
    "        return [text]\n",
    "def fetchDataFromWeb(urls):\n",
    "    r = requests.get(f\"https://quran411.com/verse-by-verse?sn={urls}\")\n",
    "    html = r.content\n",
    "    soup = bs(html,\"html.parser\")\n",
    "    div = soup.find(\"div\", {\"class\": \"ac-content\"})\n",
    "    new_div = str(div).replace(\"<br/>\",\"##\")\n",
    "    soup2 = bs(new_div,\"html.parser\")\n",
    "    total_data = []\n",
    "    for e in (soup2.text.split(\"##\")[:-1]):\n",
    "        e = e.replace(\"\\n\",\"\")\n",
    "        ayah_num = e[0]\n",
    "        e = e[3:]\n",
    "        if(\"section\" in e):\n",
    "            index = e.find(\"section\")\n",
    "            replace_word = e[index-2:]\n",
    "            e = e.replace(replace_word,\"\")\n",
    "        if(\"End Juz\" in e):\n",
    "            index = e.find(\"End Juz\")\n",
    "            replace_word = e[index-2:]\n",
    "            e = e.replace(replace_word,\"\")\n",
    "        ngrams = generate_N_grams(e,5)\n",
    "        for n in ngrams:\n",
    "            data = {\"arabic\":n,\"surat\":urls,\"ayat\":ayah_num,\"phonemes\":fuzzy.nysiis(n),\"phonemese2\":phonetics.metaphone(n),\"verse\":f\"{urls}:{ayah_num}\"}\n",
    "            total_data.append(data)\n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVSjh3zHQm28"
   },
   "outputs": [],
   "source": [
    "data = rdd_urls.flatMap(lambda x:fetchDataFromWeb(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52V9UvXorDYW"
   },
   "source": [
    "# Save data as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dN0uKe2QjIA"
   },
   "outputs": [],
   "source": [
    "data.saveAsPickleFile(\"/content/drive/MyDrive/phonemesTransData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_fP4lucEeaC"
   },
   "source": [
    "# Query Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fSMXm2jTSKE"
   },
   "source": [
    "# Importing data from pickle files and converting them into spark rdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoRktI2FPtC3"
   },
   "outputs": [],
   "source": [
    "\n",
    "phonetic_verse_data = \"/content/drive/MyDrive/romanPhonemeDistributedData\"\n",
    "quranic_verse_data = \"/content/drive/MyDrive/quranVerseDistributedData\"\n",
    "\n",
    "rdd_phonemes = sc.pickleFile(phonetic_verse_data)\n",
    "rdd_quran = sc.pickleFile(quranic_verse_data).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvgGJiLAUtQ4"
   },
   "source": [
    "# Required Preprocessing\n",
    "## As we have done majority preprocessing while creating the dataset so not much of the cleaning is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw6tjaDbQJFC"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    arabic = x[\"arabic\"]\n",
    "    phonemes_v1 = x[\"phonemes\"].replace(\" \",\"\")\n",
    "    phonemes_v2 = x[\"phonemese2\"].replace(\" \",\"\")\n",
    "    ayat = int(x[\"ayat\"])\n",
    "    surat = int(x[\"surat\"])\n",
    "    verse = x[\"verse\"]\n",
    "\n",
    "    return [arabic, phonemes_v1, phonemes_v2,ayat,surat,verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fU_yKnWYYl3_"
   },
   "outputs": [],
   "source": [
    "rdd_phonemes = rdd_phonemes.map(lambda x: preprocess_data(x)).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQFmlMPZnU31"
   },
   "source": [
    "#Function for phonetic match we use 2 types of phonemes and based on the distance we rank the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvMVxUvdrWjK"
   },
   "source": [
    "#Query and ayah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZpLpgsSTn1fH"
   },
   "outputs": [],
   "source": [
    "ayat = \"kul hoo vellahoo ehed\"\n",
    "ayat = ayat.split(\" \")\n",
    "ayat = ' '.join(ayat[0:6]) if len(ayat) > 6 else ' '.join(ayat)\n",
    "phoneme_type1 = fuzzy.nysiis(ayat)\n",
    "phoneme_type2 = phonetics.metaphone(ayat)\n",
    "broadcastVar1 = sc.broadcast(phoneme_type1)\n",
    "broadcastVar2 = sc.broadcast(phoneme_type2)\n",
    "seq = SequenceMatcher()\n",
    "seq2 = SequenceMatcher()\n",
    "\n",
    "def matchPhonemes(phon,verse,arabic,ayat):\n",
    "    '''\n",
    "    1. Phonemese type1 is extracted using nysiis phonetic algo\n",
    "    2. Phonemes type2 is extracted using metaphone algo\n",
    "    3. Phon coming from database will be compare with type1\n",
    "    5. verse will be return which will than be used to query further\n",
    "    \n",
    "    Similar to above mention. It will be evaluated on basis of sequence ratio\n",
    "    '''\n",
    "    phoneme_type1 = broadcastVar1.value\n",
    "    phoneme_type2 = broadcastVar2.value\n",
    "    try:\n",
    "        seq.set_seqs(phoneme_type1,phon)\n",
    "        if ((seq.ratio()>0.85) or ((phoneme_type1 in phon) and (seq.ratio()>0.68))):\n",
    "            seq2.set_seqs(ayat.lower(),arabic.lower())\n",
    "            if seq2.ratio()>0.55:\n",
    "                return (seq.ratio(),verse)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "phonetic_matches = rdd_phonemes.map(lambda x: matchPhonemes(x[1],x[5],x[0],ayat))\n",
    "phonetic_matches = phonetic_matches.filter(lambda x: x!=None)\n",
    "phonetic_matches = phonetic_matches.groupBy(lambda x: x[1]).mapValues(lambda x: max(x))\n",
    "phonetic_matches = phonetic_matches.sortBy(lambda x: x[1][0],False)\n",
    "phonetic_matches = phonetic_matches.map(lambda x:(x[0],x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9JNJRf1Lpyui"
   },
   "outputs": [],
   "source": [
    "final_results = rdd_quran.map(lambda x: (x[\"verse\"],x))\n",
    "final_results = final_results.join(phonetic_matches)\n",
    "final_results = final_results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4bwOgsop1QW",
    "outputId": "0fd0cfb2-1767-4802-f818-5051ba8d6fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('112:1',\n",
       "  ({'SurahName': 'surah-ikhlas',\n",
       "    'arabic': 'قُلْ هُوَ اللَّهُ أَحَدٌ',\n",
       "    'code': '112001',\n",
       "    'translation': 'Say, \"He is God, the One.',\n",
       "    'urdu_translation': 'تم فرماؤ وہ اللہ ہے وہ ایک ہے',\n",
       "    'verse': '112:1'},\n",
       "   0.875))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOgvLL7WCSjN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BDA_Project2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
